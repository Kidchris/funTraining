# -*- coding: utf-8 -*-
"""mnist_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PvxLQefEHlYCoVPO3scAvigNu8MpvJWF
"""

import numpy as np;
import matplotlib.pyplot as plt;
import tensorflow as tf;
import random

"""Let's load the data and store it to train and test files"""

(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()

"""A preview"""

plt.figure(figsize=(20, 15))

for i, image in zip(range(1, 40+1), X_train):
    choice = random.choice(range(len(X_train)))
    plt.subplot(5, 8, i)
    plt.imshow(X_train[choice])
    plt.title(f"{y_train[choice]}")

shape = X_train.shape[1:]
shape

print(np.unique(y_train))
train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.0,
                                                            horizontal_flip=True,
                                                            vertical_flip=True,
                                                            width_shift_range=0.3,
                                                            height_shift_range=0.3,
                                                            zoom_range=.3
                                                        )

train_dataset = train_gen.flow(x=X_train, y=y_train, batch_size=32, seed=42)
test_dataset = train_gen.flow(x=X_test, y=y_test, batch_size=32, seed=42)

X_train = (X_train/255.0).reshape(-1, 28, 28, 1)
X_test = (X_test/255.0).reshape(-1, 28, 28, 1)

x = next(test_dataset)
print(type(x))
plt.figure(figsize=(10, 7))

for i, image in zip(range(1, 20+1), x):
    choice = random.choice(range(len(x)))
    plt.subplot(5, 8, i)
    plt.imshow(x[0][choice].reshape(28, 28))
    plt.title(f"{x[-1][choice]}")

from keras.models import Sequential
# from keras.applications.vgg16 import VGG16
from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten

model = Sequential()
model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(Conv2D(32, (3, 3), activation='relu', padding="same"))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Conv2D(128, (3, 3), activation='relu', padding="same"))
model.add(Conv2D(256, (3, 3), activation='relu', padding="same"))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dropout(.2))
model.add(Dense(128, activation='relu'))
model.add(Dropout(.25))
model.add(Dense(64, activation='relu'))
model.add(Dense(10, activation='softmax'))

model.summary()

model.compile(loss="sparse_categorical_crossentropy",optimizer="adam",  metrics=["acc"])

res = model.fit(X_train, y_train, epochs=10)

plt.figure(figsize=(9,7))
plt.tight_layout()
plt.plot(res.history["loss"], label="Training loss", c="r")
# plt.plot(res.history["val_loss"], label="Validation loss", c="k")
plt.plot(res.history["acc"], label="Training accuracy", c="b")
# plt.plot(res.history["val_acc"], label="Validation accuracy", c="g")
plt.legend()
plt.title("Accuracy/Loss")
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns


prediction = model.predict(X_test).argmax(axis=1)
print("Score Accuracy : ", model.evaluate(X_test, y_test))
sns.heatmap(confusion_matrix(y_test, prediction), annot=True, cbar=False, cmap='cool', fmt="d")

# Show some misclassified examples
size = 40
misclassified_idx = np.where(prediction !=y_test )[0]

plt.figure(figsize=(20, 15))
for k, image in zip(range(1, size+1), X_test):
    i = np.random.choice(misclassified_idx)
    plt.subplot(5, 8, k)
    plt.imshow(X_test[i].reshape(28, 28))
    plt.title("True: %s Pred: %s" % (y_test[i], prediction[i]));

